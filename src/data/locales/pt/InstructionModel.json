{
  "loading": "Carregando...",
  "delete": "Excluir",
  "title": "Instrução Modo a seguir",
  "description": "Inscreva-se em uma conversa com o LLM de 1 bit. ",
  "commandOptions": "Opções de comando",
  "numberOfTokens": "Tokens máximos por turno",
  "model": "Modelo",
  "threads": "Tópicos",
  "contextSize": "Tamanho do contexto",
  "temperature": "Temperatura",
  "prompt": "Incitar",
  "numberOfTokensInfo": "O número máximo de tokens (palavras) a IA gerará em cada resposta.",
  "modelInfo": "Selecione o quantizado '{{fileFormat}}'Arquivo de modelo gerado usando o Microsoft's BitNet'{{script}}'Script.",
  "threadsInfo": "O número de threads a serem usados ​​para executar a inferência, limitada ao número de threads disponíveis na CPU.",
  "contextSizeInfo": "O tamanho do contexto imediato determina quanto do histórico de conversas é considerado durante a inferência.",
  "temperatureInfo": "Controla a aleatoriedade do texto gerado. ",
  "promptInfo": "Este é o texto inicial que o modelo usará para começar a gerar a saída.",
  "runInference": "Executar inferência",
  "stopInference": "Pare a inferência",
  "response": "Resposta",
  "license": "{{license}} Código licenciado",
  "builtWith": "construído com",
  "noModelSelected": "Nenhum modelo selecionado",
  "systemPrompt": "Prompt de sistema",
  "systemPromptInfo": "Defina o papel ou personalidade da IA ​​(por exemplo, 'Você é um assistente útil.', 'Você é um pirata.'). ",
  "systemPromptPlaceholder": "Insira o prompt do sistema aqui ...",
  "startConversation": "Inicie a conversa",
  "starting": "Começando ...",
  "stopConversation": "Pare de conversa",
  "chat": "Bater papo",
  "typing": "Ai está digitando ...",
  "typeMessagePlaceholder": "Digite sua mensagem aqui ...",
  "sendMessage": "Enviar mensagem",
  "you": "Você",
  "ai": "Ai",
  "youAvatar": "Você",
  "aiAvatar": "Ai",
  "regenerate": "Regenerar Resposta",
  "copy": "Copiar Resposta",
  "copied": "Copiado!",
  "expand": "Expandir Resposta",
  "collapse": "Recolher Resposta"
}