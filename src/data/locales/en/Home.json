{
    "title": "Electron BitNet Inference Tool",
    "description": "Microsoft released BitNet as their official inference framework for 1-bit LLMs which runs on CPUs, try it out below!",
    "commandOptions": "Command Options",
    "numberOfTokens": "Number of tokens to predict",
    "model": "Model",
    "threads": "Threads",
    "contextSize": "Context size",
    "temperature": "Temperature",
    "prompt": "Prompt",
    "numberOfTokensInfo": "This is the quantity of tokens (words) to generate from running the inference framework.",
    "modelInfo": "Input the path to the quantized '{{fileFormat}}' model file generated using Microsoft's BitNet '{{script}}' script.",
    "threadsInfo": "The number of threads to use for running the inference, limited to the number of threads available on the CPU.",
    "contextSizeInfo": "The size of the prompt context determines how much of the prompt is considered during inference.",
    "temperatureInfo": "A hyperparameter that controls the randomness of the generated text, lower values make the text more deterministic.",
    "promptInfo": "This is the initial text that the model will use to start generating the output.",
    "runInference": "Run Inference",
    "stopInference": "Stop Inference",
    "response": "Response",
    "license": "{{license}} Licensed code",
    "builtWith": "built with"
}