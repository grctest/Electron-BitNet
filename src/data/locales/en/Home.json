{
    "title": "Electron BitNet Inference Tool",
    "description": "Microsoft released bitnet.cpp as their official inference framework for 1-bit LLMs (e.g., BitNet b1.58) which runs on CPUs; enjoy!",
    "commandOptions": "Command Options",
    "numberOfTokens": "Number of tokens to predict",
    "model": "Model",
    "threads": "Threads",
    "contextSize": "Context size",
    "temperature": "Temperature",
    "prompt": "Prompt",
    "numberOfTokensInfo": "This is the quantity of tokens (words) to generate from running the inference framework.",
    "modelInfo": "Input the path to the quantized '{{fileFormat}}' model file generated using the Microsoft's BitNet '{{script}}' script.",
    "threadsInfo": "The number of threads to use for running the inference. Default value is 2.",
    "contextSizeInfo": "Size of the prompt context. This determines how much of the prompt is considered during inference.",
    "temperatureInfo": "A hyperparameter that controls the randomness of the generated text. Lower values make the text more deterministic.",
    "promptInfo": "The prompt to generate text from. This is the initial text that the model will use to start generating the output.",
    "runInference": "Run Inference",
    "stopInference": "Stop Inference",
    "response": "Response",
    "license": "{{license}} Licensed code",
    "builtWith": "built with"
}