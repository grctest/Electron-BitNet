{
  "title": "Modalità seguente istruzioni",
  "description": "Impegnarsi in una conversazione con l'LLM a 1 bit. ",
  "commandOptions": "Opzioni di comando",
  "numberOfTokens": "Token massimi per turno",
  "model": "Modello",
  "threads": "Discussioni",
  "contextSize": "Dimensione del contesto",
  "temperature": "Temperatura",
  "prompt": "Richiesta",
  "numberOfTokensInfo": "Il numero massimo di token (parole) l'IA genererà in ogni risposta.",
  "modelInfo": "Seleziona il quantizzato '{{fileFormat}}\"File modello generato utilizzando BitNet di Microsoft\"{{script}}'Script.",
  "threadsInfo": "Il numero di thread da utilizzare per l'esecuzione dell'inferenza, limitato al numero di thread disponibili sulla CPU.",
  "contextSizeInfo": "La dimensione del contesto rapido determina la quantità di cronologia della conversazione durante l'inferenza.",
  "temperatureInfo": "Controlla la casualità del testo generato. ",
  "promptInfo": "Questo è il testo iniziale che il modello utilizzerà per iniziare a generare l'output.",
  "runInference": "Eseguire l'inferenza",
  "stopInference": "Fermare l'inferenza",
  "response": "Risposta",
  "license": "{{license}} Codice autorizzato",
  "builtWith": "costruito con",
  "noModelSelected": "Nessun modello selezionato",
  "systemPrompt": "Prompt del sistema",
  "systemPromptInfo": "Definisci il ruolo o la personalità dell'intelligenza artificiale (ad esempio, \"sei un assistente utile\", sei un pirata. \"). ",
  "systemPromptPlaceholder": "Immettere il prompt del sistema qui ...",
  "startConversation": "Inizia la conversazione",
  "starting": "Di partenza...",
  "stopConversation": "Fermare la conversazione",
  "chat": "Chiacchierata",
  "typing": "Ai sta digitando ...",
  "typeMessagePlaceholder": "Digita il tuo messaggio qui ...",
  "sendMessage": "Invia messaggio",
  "you": "Voi",
  "ai": "AI",
  "youAvatar": "Voi",
  "aiAvatar": "AI",
  "regenerate": "Rigenera risposta",
  "copy": "Copia risposta",
  "copied": "Copiato!",
  "expand": "Espandi risposta",
  "collapse": "Comprimi risposta"
}