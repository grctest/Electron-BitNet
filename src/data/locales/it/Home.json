{
  "title": "Strumento di inferenza BitNet di Electron",
  "description": "Microsoft ha rilasciato BitNet come framework di inferenza ufficiale per LLM a 1 bit che funziona su CPU, provalo di seguito!",
  "commandOptions": "Opzioni di comando",
  "numberOfTokens": "Numero di token da prevedere",
  "model": "Modello",
  "threads": "Discussioni",
  "contextSize": "Dimensione del contesto",
  "temperature": "Temperatura",
  "prompt": "Richiesta",
  "numberOfTokensInfo": "Questa è la quantità di token (parole) da generare dall'esecuzione del framework di inferenza.",
  "modelInfo": "Inserisci il percorso del \"quantizzato\"{{fileFormat}}'file modello generato utilizzando BitNet di Microsoft'{{script}}' copione.",
  "threadsInfo": "Il numero di thread da utilizzare per eseguire l'inferenza, limitato al numero di thread disponibili sulla CPU.",
  "contextSizeInfo": "La dimensione del contesto del prompt determina la parte del prompt che viene considerata durante l'inferenza.",
  "temperatureInfo": "Un iperparametro che controlla la casualità del testo generato, valori più bassi rendono il testo più deterministico.",
  "promptInfo": "Questo è il testo iniziale che il modello utilizzerà per iniziare a generare l'output.",
  "runInference": "Esegui l'inferenza",
  "stopInference": "Interrompi l'inferenza",
  "response": "Risposta",
  "license": "{{license}} Codice concesso in licenza",
  "builtWith": "costruito con"
}