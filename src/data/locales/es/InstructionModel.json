{
  "loading": "Cargando...",
  "delete": "Borrar",
  "title": "Modo de instrucción siguiente",
  "description": "Participe en una conversación con el LLM de 1 bits. ",
  "commandOptions": "Opciones de comando",
  "numberOfTokens": "Tokens máximo por turno",
  "model": "Modelo",
  "threads": "Trapos",
  "contextSize": "Tamaño de contexto",
  "temperature": "Temperatura",
  "prompt": "Inmediato",
  "numberOfTokensInfo": "El número máximo de tokens (palabras) que la IA generará en cada respuesta.",
  "modelInfo": "Seleccione el cuantizado '{{fileFormat}}'Archivo de modelo generado utilizando BitNet de Microsoft'{{script}}' guion.",
  "threadsInfo": "El número de subprocesos a usar para ejecutar la inferencia, limitado al número de subprocesos disponibles en la CPU.",
  "contextSizeInfo": "El tamaño del contexto rápido determina cuánto del historial de conversación se considera durante la inferencia.",
  "temperatureInfo": "Controla la aleatoriedad del texto generado. ",
  "promptInfo": "Este es el texto inicial que el modelo usará para comenzar a generar la salida.",
  "runInference": "Inferencia de ejecución",
  "stopInference": "Detener la inferencia",
  "response": "Respuesta",
  "license": "{{license}} Código con licencia",
  "builtWith": "construido con",
  "noModelSelected": "Ningún modelo seleccionado",
  "systemPrompt": "Aviso del sistema",
  "systemPromptInfo": "Defina el papel o la personalidad de la IA (por ejemplo, 'usted es un asistente útil', 'usted es un pirata'). ",
  "systemPromptPlaceholder": "Ingrese la solicitud del sistema aquí ...",
  "startConversation": "Iniciar conversación",
  "starting": "A partir de...",
  "stopConversation": "Detener la conversación",
  "chat": "Charlar",
  "typing": "Ai está escribiendo ...",
  "typeMessagePlaceholder": "Escriba su mensaje aquí ...",
  "sendMessage": "Enviar un mensaje",
  "you": "Tú",
  "ai": "AI",
  "youAvatar": "Tú",
  "aiAvatar": "AI",
  "regenerate": "Regenerar respuesta",
  "copy": "Copiar respuesta",
  "copied": "¡Copiado!",
  "expand": "Expandir respuesta",
  "collapse": "Contraer respuesta"
}